# å°å…¥è‡ªå®šç¾©çš„å¿«å–èˆ‡åç¨±ç´€éŒ„æª”è·¯å¾‘
from config.paths import cachepath, cachepath_namelog

# å°å…¥è‡ªå®šç¾©çš„åŸºæœ¬éš¨æ©Ÿç·¨ç¢¼ç”¢ç”Ÿå‡½å¼
from StevenTricks.code_utils import basic_code

# å°å…¥è‡ªå®šç¾©çš„æª”æ¡ˆæ•´ç†å‡½å¼ï¼ˆå«ç›®éŒ„èµ°è¨ªèˆ‡æ¬„ä½è§£æï¼‰
from StevenTricks.file_utils import PathWalk_df

# å°å…¥è‡ªå®šç¾©çš„ pickle å­˜å–å·¥å…·
from StevenTricks.file_utils import pickleload, picklesave

# æ¨™æº–å‡½å¼åº«ï¼Œç”¨ä¾†è™•ç†ç›®éŒ„æ¸…ç©ºèˆ‡é‡æ–°å»ºç«‹
import shutil
from pathlib import Path


# ğŸ”¹ è¦å»ºç«‹å¿«å–è¨˜éŒ„çš„è³‡æ–™é …ç›®ï¼ˆæœƒå°æ¯ä¸€å€‹å»ºç«‹å”¯ä¸€ codeï¼‰
data_list = ["å€‹åˆ¥ç”¢æ¥­æˆäº¤æ¯”é‡", "ç”¢æ¥­åŠä¸‰å¤§æ³•äºº", "ç”¢æ¥­åŠèè³‡èåˆ¸"]


def update_cache(data_list, cache_dir, namelog_path, code_length=4, avoid_mode="fuzzy"):
    """
    æ ¹æ“š data_list å’Œç¾æœ‰çš„ cachename_log é€²è¡ŒåŒæ­¥æ›´æ–°ï¼š
    - æ¸…é™¤å¤±æ•ˆçš„ codeï¼ˆåœ¨ cache è³‡æ–™å¤¾ä¸­æ‰¾ä¸åˆ°çš„ï¼‰
    - æ–°å¢ data_list ä¸­çš„æ–°é …ç›®
    - ä¿ç•™æœ‰æ•ˆçš„ code

    åƒæ•¸èªªæ˜ï¼š
    - data_list: ä½¿ç”¨è€…é—œå¿ƒçš„è³‡æ–™æ¨™ç±¤åˆ—è¡¨
    - cache_dir: å¿«å–è³‡æ–™å„²å­˜çš„è³‡æ–™å¤¾è·¯å¾‘
    - namelog_path: ç”¨ä¾†å„²å­˜ log.pkl çš„è·¯å¾‘ï¼Œå…§å®¹æ˜¯æ¯ç­†è³‡æ–™å°æ‡‰çš„ code
    - code_length: æ¯å€‹ code é è¨­é•·åº¦ï¼ˆéš¨æ©Ÿç·¨ç¢¼ + æ•¸å­—ç·¨ç¢¼ï¼‰
    - avoid_mode: é¿å…é‡è¤‡çš„æ¯”å°æ–¹å¼ï¼Œ"fuzzy"ï¼ˆæ¨¡ç³Šæ¯”å°ï¼‰æˆ– "exact"ï¼ˆå®Œå…¨ç›¸åŒï¼‰
    """

    # å°‡å‚³å…¥çš„è·¯å¾‘å­—ä¸²è½‰ç‚º Path ç‰©ä»¶ä»¥åˆ©å¾ŒçºŒæ“ä½œ
    cache_dir = Path(cache_dir)
    namelog_path = Path(namelog_path)

    # ğŸ”¸ å–å¾—ç›®å‰ cache ç›®éŒ„ä¸‹æ‰€æœ‰ .pkl æª”æ¡ˆçš„ code å‰ç¶´ï¼ˆé€éæª”åå‰æ®µï¼‰
    cache_files = [f.stem.split("_")[0] for f in cache_dir.glob("*.pkl")]

    # ğŸ”¸ å¦‚æœ namelog å·²å­˜åœ¨ï¼Œä»£è¡¨å·²æœ‰æ­·å²å°æ‡‰è¨˜éŒ„ï¼Œè¦æ¯”å°èˆ‡æ›´æ–°
    if namelog_path.exists():
        log_df = {}  # æœ€çµ‚æ›´æ–°çš„å°æ‡‰è¡¨
        log_df_old = pickleload(namelog_path)  # è®€å…¥æ­·å²è¨˜éŒ„

        # ğŸ”¸ ä½¿ç”¨ PathWalk_df å–å¾—æ‰€æœ‰å¿«å–æª”æ¡ˆå°æ‡‰æ¬„ä½ï¼ˆåŒ…å« code æ¬„ï¼‰
        cache_walk = PathWalk_df(
            cache_dir,
            fileinclude=[".pkl"],
            name_format="code_time_order.ext"  # å‘½åæ ¼å¼å”åŠ©è§£æå‡º code æ¬„
        )

        # ğŸ”¸ æŠ“å‡ºç›®å‰ cache è£¡é¢æ‰€æœ‰æœ‰æ•ˆçš„ code åˆ—è¡¨ï¼ˆé¿å…é‡è¤‡ä½¿ç”¨ï¼‰
        avoid_list = cache_walk["code"].unique().tolist()

        # ğŸ”¸ å°æ¯ä¸€ç­†æ­·å²è¨˜éŒ„æª¢æŸ¥æ˜¯å¦é‚„æœ‰æ•ˆ
        for key, code in log_df_old.items():
            if code in avoid_list:
                # âœ… æ­¤ code åœ¨ cache ä¸­ä»ç„¶æœ‰æ•ˆï¼Œä¿ç•™
                log_df[key] = code
            else:
                # âŒ æ­¤ code å·²å¤±æ•ˆï¼Œéœ€åˆªé™¤å…¶å°æ‡‰æª”æ¡ˆï¼ˆè‹¥æ®˜ç•™ï¼‰ä¸¦é‡å»ºæ–°çš„ code
                for filepath in cache_walk[cache_walk["code"] == code]["path"]:
                    p = Path(filepath)
                    if p.exists():
                        p.unlink()  # åˆªé™¤è©²æª”æ¡ˆ

                # ğŸ”¸ ä½¿ç”¨ basic_code å»ºç«‹æ–°çš„å”¯ä¸€ codeï¼Œä¸¦é¿å…èˆ‡ç¾æœ‰é‡è¤‡
                code = basic_code(length=code_length, match_mode=avoid_mode, avoid_list=[code])
                log_df[key] = code

    else:
        # ğŸ”¸ è‹¥ namelog ä¸å­˜åœ¨ï¼Œä»£è¡¨é¦–æ¬¡å»ºç«‹ï¼Œéœ€æ¸…ç©ºè³‡æ–™å¤¾é‡å»ºå¿«å–ç›®éŒ„
        shutil.rmtree(cache_dir)  # ç§»é™¤æ•´å€‹è³‡æ–™å¤¾ï¼ˆè‹¥å­˜åœ¨ï¼‰
        cache_dir.mkdir(parents=True, exist_ok=True)  # å»ºç«‹æ–°çš„ç©ºè³‡æ–™å¤¾

        # ğŸ”¸ ç‚ºæ¯å€‹è³‡æ–™é …ç›®ç”¢ç”Ÿä¸€çµ„ä¸é‡è¤‡ code
        code = basic_code(length=code_length, match_mode=avoid_mode, count=len(data_list))

        # ğŸ”¸ å»ºç«‹åç¨±èˆ‡ code çš„å°æ‡‰å­—å…¸
        log_df = dict(zip(data_list, code))

    # ğŸ”¸ å°‡æ›´æ–°å¾Œçš„ code å°æ‡‰è¡¨å„²å­˜ç‚º pickle
    picklesave(log_df, namelog_path)

    # âœ… å›å‚³æœ€å¾Œçš„å°æ‡‰è¡¨çµæœ
    return log_df


# ğŸ”¹ è‹¥ç›´æ¥åŸ·è¡Œæ­¤æ¨¡çµ„ï¼Œå°‡åŸ·è¡Œæ›´æ–°æµç¨‹ä¸¦å°å‡ºçµæœ
if __name__ == "__main__":
    cache_data = update_cache(data_list, cachepath, cachepath_namelog, 5, "fuzzy")
